"""
UIDAI Aadhaar - Strategic Vulnerability Analysis (Phase 12)
============================================================
The "Meta-Analysis" combining Themes 1, 2, and 3.
Goal: Predict Infrastructure Failure Points by correlating Forecasts (Stress) with Historial Efficiency (Fragility).

Inputs: 'uidai_gold_master.csv', 'api_data_aadhar_biometric' (for forensic entropy check)
Outputs: Risk Matrix Visualization, Red List of At-Risk States.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy.stats import zscore
import warnings
warnings.filterwarnings('ignore')

sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.family'] = 'sans-serif'

base_path = Path(r"c:\Users\sagar\Downloads\uidai dataset")
processed_path = base_path / "processed"
output_path = base_path / "strategic_outputs"
output_path.mkdir(exist_ok=True)

print("=" * 80)
print("UIDAI STRATEGIC VULNERABILITY ASSESSMENT")
print("=" * 80)

# =============================================================================
# 1. LOAD DATA
# =============================================================================
print("\n[1/4] Loading Gold Master Data...")
df = pd.read_csv(processed_path / "uidai_gold_master.csv")
print(f"  Records: {len(df):,}")

# =============================================================================
# 2. CALCULATE METRICS (AGGREGATION)
# =============================================================================
print("\n[2/4] Calculating State-Level Strategic Metrics...")

state_stats = df.groupby("state_clean").agg(
    Total_Volume=("total_count", "sum"),
    Daily_Avg=("total_count", "mean"),
    Daily_Std=("total_count", "std"),
    Records=("total_count", "count"),
    Biometric_Vol=("total_count", lambda x: x[df["type"]=="Biometric"].sum()),
    Demographic_Vol=("total_count", lambda x: x[df["type"]=="Demographic"].sum())
).reset_index()

# Metric 1: FRAGILITY (Inverted Efficiency)
# Low Bio/Demo ratio = inefficient/manual dependent. High Anomaly Rate = Unstable.
# We also include 'Intermittency' (days with 0 data vs active days) if possible, but simpler:
# Fragility = (Demographic / Total) * (Volatility)
# Actually, let's stick to the Themes:
# Theme 2 Efficiency = Bio / (Demo + 1)
state_stats["Efficiency_Ratio"] = state_stats["Biometric_Vol"] / (state_stats["Demographic_Vol"] + 1)
# Normalize Efficiency (Higher is better, so Fragility is inverse)
state_stats["Fragility_Score"] = 1 / (state_stats["Efficiency_Ratio"] + 0.1) 

# Metric 2: STRESS (Forecasted Demand Intensity)
# We can't run Prophet for every state here efficiently. 
# Proxy for Forecast Stress: Momentum (Growth Rate of last 30 days vs prev 30 days)
# We need to compute momentum per state.
print("  > Computing Growth Momentum per State...")
state_momentum = []

df["date"] = pd.to_datetime(df["date"])
latest_date = df["date"].max()
last_30_start = latest_date - pd.Timedelta(days=30)
prev_30_start = last_30_start - pd.Timedelta(days=30)

for state in state_stats["state_clean"]:
    subset = df[df["state_clean"] == state]
    vol_last_30 = subset[subset["date"] > last_30_start]["total_count"].sum()
    vol_prev_30 = subset[(subset["date"] > prev_30_start) & (subset["date"] <= last_30_start)]["total_count"].sum()
    
    if vol_prev_30 > 0:
        growth = (vol_last_30 - vol_prev_30) / vol_prev_30
    else:
        growth = 0.0
    state_momentum.append(growth)

state_stats["Demand_Growth_Rate"] = state_momentum

# Final Risk Score = Fragility * Demand Growth (If Growth > 0, else 0 risk of crash)
# Normalize Prediction
state_stats["Stress_Index"] = state_stats["Demand_Growth_Rate"] * np.log1p(state_stats["Total_Volume"])

# Normalize for Plotting (0-100 Scale)
def normalize(series):
    return 100 * (series - series.min()) / (series.max() - series.min())

state_stats["Fragility_Norm"] = normalize(state_stats["Fragility_Score"])
state_stats["Stress_Norm"] = normalize(state_stats["Stress_Index"])

# =============================================================================
# 3. IDENTIFY RED LIST (Risk Quadrants)
# =============================================================================
print("\n[3/4] Identifying 'Red List' (High Stress + High Fragility)...")

# High Risk threshold: Top 25% in both Stress and Fragility?
# Or just Quadrant plot.

# Quadrant Analysis
avg_fragility = state_stats["Fragility_Norm"].mean()
avg_stress = state_stats["Stress_Norm"].mean()

red_list = state_stats[
    (state_stats["Fragility_Norm"] > avg_fragility) & 
    (state_stats["Stress_Norm"] > avg_stress)
].sort_values("Stress_Norm", ascending=False)

print(f"  CRITICAL COUNT: {len(red_list)} States in Red Quadrant.")
print("  Top 5 Critical States:")
for i, row in red_list.head(5).iterrows():
    print(f"    - {row['state_clean']} (Stress: {row['Stress_Norm']:.1f}, Fragility: {row['Fragility_Norm']:.1f})")

# =============================================================================
# 4. VISUALIZATION
# =============================================================================
print("\n[4/4] Generating Strategic Risk Matrix...")

plt.figure(figsize=(12, 10))

# Plot Scatter
sns.scatterplot(
    data=state_stats,
    x="Stress_Norm",
    y="Fragility_Norm",
    s=state_stats["Total_Volume"] / 50000, # Size by Volume
    color="#95a5a6",
    alpha=0.6,
    edgecolor="black"
)

# Highlight Red List
sns.scatterplot(
    data=red_list,
    x="Stress_Norm",
    y="Fragility_Norm",
    s=red_list["Total_Volume"] / 50000,
    color="#c0392b",
    edgecolor="black",
    label="CRITICAL RISK (Red List)"
)

# Quadrant Lines
plt.axvline(x=avg_stress, color='gray', linestyle='--', alpha=0.5, label="Avg Stress")
plt.axhline(y=avg_fragility, color='gray', linestyle='--', alpha=0.5, label="Avg Fragility")

# Labels
for i, row in state_stats.iterrows():
    # Label if in Red List or enormous volume
    if row["state_clean"] in red_list["state_clean"].values or row["Total_Volume"] > state_stats["Total_Volume"].quantile(0.9):
        plt.text(
            row["Stress_Norm"]+1, 
            row["Fragility_Norm"]+1, 
            row["state_clean"], 
            fontsize=9
        )

# Quadrant Anotation
plt.text(95, 95, "CRITICAL FAILURE ZONE\n(High Growth + Low Efficiency)", 
         ha='right', va='top', color='#c0392b', fontweight='bold', fontsize=12,
         bbox=dict(facecolor='white', alpha=0.8, edgecolor='#c0392b'))

plt.text(5, 5, "SAFE ZONE\n(Stable + Efficient)", 
         ha='left', va='bottom', color='#27ae60', fontweight='bold', fontsize=12)

plt.title("Strategic Vulnerability Matrix: Where will the System Break?\n(Theme 1+2+3 Integrated Analysis)", fontsize=16)
plt.xlabel("Future Stress Index (Based on Demand Momentum)", fontsize=12)
plt.ylabel("System Fragility (Inefficiency Score)", fontsize=12)
plt.legend(loc='lower right')

plt.tight_layout()
plt.savefig(output_path / "strategic_risk_matrix.png")
print(f"  Saved: strategic_risk_matrix.png")

# Save Red List Report
red_path = output_path / "critical_red_list.csv"
red_list[["state_clean", "Total_Volume", "Efficiency_Ratio", "Demand_Growth_Rate", "Stress_Norm", "Fragility_Norm"]].to_csv(red_path, index=False)
print(f"  Saved Red List: {red_path}")

print("\nSTRATEGIC ANALYSIS COMPLETE.")
